{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=r'C:\\Users\\ASUS\\Desktop\\PBL\\data\\resampled_dataset.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN-lstm after reducing overfitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, Flatten, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder,MinMaxScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "def create_cnn_lstm_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        # First Conv1D block with L2 regularization\n",
    "        Conv1D(filters=32, kernel_size=3, activation='relu', \n",
    "               kernel_regularizer=l2(0.001), input_shape=input_shape),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        # Second Conv1D block with L2 regularization\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu',\n",
    "               kernel_regularizer=l2(0.001)),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        # LSTM layers with dropout and recurrent dropout\n",
    "        LSTM(50, return_sequences=True, dropout=0.3, recurrent_dropout=0.3,\n",
    "             kernel_regularizer=l2(0.001)),\n",
    "        \n",
    "        LSTM(50, dropout=0.3, recurrent_dropout=0.3,\n",
    "             kernel_regularizer=l2(0.001)),\n",
    "        \n",
    "        # Dense layer with L2 regularization\n",
    "        Dense(50, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        \n",
    "        # Output layer\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X, y, test_size=0.2, val_size=0.2):\n",
    "    \"\"\"Preprocess data: scale features and split into train, test, validation sets\"\"\"\n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, \n",
    "                                                        stratify=y, random_state=42)\n",
    "    \n",
    "    # Split train set into train and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=val_size, \n",
    "                                                      stratify=y_train, random_state=42)\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_val = scaler.transform(X_val)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # Reshape for CNN (samples, timesteps, features)\n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "    X_val = X_val.reshape(X_val.shape[0], X_val.shape[1], 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "def data_augmentation(X, y):\n",
    "    \"\"\"Apply data augmentation to increase dataset size and variety\"\"\"\n",
    "    X_augmented = [X]\n",
    "    y_augmented = [y]\n",
    "    \n",
    "    # Adding random noise\n",
    "    noise_factor = 0.05\n",
    "    X_noise = X + np.random.normal(0, noise_factor, X.shape)\n",
    "    X_augmented.append(X_noise)\n",
    "    y_augmented.append(y)\n",
    "    \n",
    "    # Magnitude scaling\n",
    "    scale_factor = np.random.uniform(0.8, 1.2)\n",
    "    X_scaled = X * scale_factor\n",
    "    X_augmented.append(X_scaled)\n",
    "    y_augmented.append(y)\n",
    "    \n",
    "    # Time shifting\n",
    "    shift = np.random.randint(1, 3)\n",
    "    X_shifted = np.roll(X, shift, axis=1)\n",
    "    X_augmented.append(X_shifted)\n",
    "    y_augmented.append(y)\n",
    "    \n",
    "    # Combine augmented data\n",
    "    X_aug = np.vstack(X_augmented)\n",
    "    y_aug = np.hstack(y_augmented)\n",
    "    \n",
    "    # Shuffle the augmented data\n",
    "    indices = np.arange(X_aug.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    X_aug = X_aug[indices]\n",
    "    y_aug = y_aug[indices]\n",
    "    \n",
    "    return X_aug, y_aug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def focal_loss(gamma=2., alpha=0.25):\n",
    "    \"\"\"\n",
    "    Focal loss for dealing with class imbalance\n",
    "    \"\"\"\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1 + K.epsilon())) - \\\n",
    "               K.sum((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0 + K.epsilon()))\n",
    "    return focal_loss_fixed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train, X_val, y_val, input_shape, num_classes, \n",
    "                batch_size=64, epochs=50, use_focal_loss=False):\n",
    "    \"\"\"Train the CNN-LSTM model with all overfitting prevention techniques\"\"\"\n",
    "    \n",
    "    # Apply data augmentation to increase training data diversity\n",
    "    X_train_aug, y_train_aug = data_augmentation(X_train, y_train)\n",
    "    \n",
    "    # Calculate class weights for imbalanced data\n",
    "    class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "    class_weight_dict = dict(enumerate(class_weights))\n",
    "    \n",
    "    # Create model\n",
    "    model = create_cnn_lstm_model(input_shape, num_classes)\n",
    "    \n",
    "    # Use focal loss for imbalanced data if specified\n",
    "    if use_focal_loss:\n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=0.001),\n",
    "            loss=focal_loss(),\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "    \n",
    "    # Print model summary\n",
    "    model.summary()\n",
    "    \n",
    "    # Define callbacks for early stopping and learning rate reduction\n",
    "    callbacks = [\n",
    "        # Early stopping to prevent overfitting\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss', \n",
    "            patience=10, \n",
    "            restore_best_weights=True, \n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # Learning rate scheduler - reduce learning rate when stuck\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss', \n",
    "            factor=0.5, \n",
    "            patience=5, \n",
    "            min_lr=1e-6, \n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # Model checkpoint to save best model\n",
    "        ModelCheckpoint(\n",
    "            'best_model.h5', \n",
    "            monitor='val_loss', \n",
    "            save_best_only=True, \n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train_aug, y_train_aug,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=callbacks,\n",
    "        class_weight=class_weight_dict,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"Evaluate model performance and visualize results\"\"\"\n",
    "    \n",
    "    # Predict on test data\n",
    "    y_pred_prob = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "    \n",
    "    # Print classification report\n",
    "    print('\\nClassification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate test accuracy\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "    print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "    \n",
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training and validation metrics\"\"\"\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>Total Length of Bwd Packets</th>\n",
       "      <th>Fwd Packet Length Max</th>\n",
       "      <th>Fwd Packet Length Min</th>\n",
       "      <th>Fwd Packet Length Mean</th>\n",
       "      <th>Fwd Packet Length Std</th>\n",
       "      <th>...</th>\n",
       "      <th>min_seg_size_forward</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53</td>\n",
       "      <td>286370</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>266</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>741</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>178</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>31410</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>174</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53551</td>\n",
       "      <td>4748</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>443</td>\n",
       "      <td>5661084</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>635</td>\n",
       "      <td>168</td>\n",
       "      <td>517</td>\n",
       "      <td>0</td>\n",
       "      <td>90.714286</td>\n",
       "      <td>190.707205</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>153901.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153901</td>\n",
       "      <td>153901</td>\n",
       "      <td>5507135.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5507135</td>\n",
       "      <td>5507135</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Destination Port  Flow Duration  Total Fwd Packets  Total Backward Packets  \\\n",
       "0                53         286370                  2                       2   \n",
       "1                53            741                  2                       2   \n",
       "2                53          31410                  2                       2   \n",
       "3             53551           4748                  2                       0   \n",
       "4               443        5661084                  7                       4   \n",
       "\n",
       "   Total Length of Fwd Packets  Total Length of Bwd Packets  \\\n",
       "0                           80                          266   \n",
       "1                           54                          178   \n",
       "2                           60                          174   \n",
       "3                           12                            0   \n",
       "4                          635                          168   \n",
       "\n",
       "   Fwd Packet Length Max  Fwd Packet Length Min  Fwd Packet Length Mean  \\\n",
       "0                     40                     40               40.000000   \n",
       "1                     27                     27               27.000000   \n",
       "2                     30                     30               30.000000   \n",
       "3                      6                      6                6.000000   \n",
       "4                    517                      0               90.714286   \n",
       "\n",
       "   Fwd Packet Length Std  ...  min_seg_size_forward  Active Mean  Active Std  \\\n",
       "0               0.000000  ...                    32          0.0         0.0   \n",
       "1               0.000000  ...                    32          0.0         0.0   \n",
       "2               0.000000  ...                    32          0.0         0.0   \n",
       "3               0.000000  ...                    20          0.0         0.0   \n",
       "4             190.707205  ...                    32     153901.0         0.0   \n",
       "\n",
       "   Active Max  Active Min  Idle Mean  Idle Std  Idle Max  Idle Min   Label  \n",
       "0           0           0        0.0       0.0         0         0  BENIGN  \n",
       "1           0           0        0.0       0.0         0         0  BENIGN  \n",
       "2           0           0        0.0       0.0         0         0  BENIGN  \n",
       "3           0           0        0.0       0.0         0         0  BENIGN  \n",
       "4      153901      153901  5507135.0       0.0   5507135   5507135  BENIGN  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load dataset\n",
    "df = pd.read_csv(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(746117, 79)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
      "  sqr = _ensure_numeric((avg - values) ** 2)\n",
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
      "  sqr = _ensure_numeric((avg - values) ** 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>Total Length of Bwd Packets</th>\n",
       "      <th>Fwd Packet Length Max</th>\n",
       "      <th>Fwd Packet Length Min</th>\n",
       "      <th>Fwd Packet Length Mean</th>\n",
       "      <th>Fwd Packet Length Std</th>\n",
       "      <th>...</th>\n",
       "      <th>act_data_pkt_fwd</th>\n",
       "      <th>min_seg_size_forward</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>746117.000000</td>\n",
       "      <td>7.461170e+05</td>\n",
       "      <td>746117.000000</td>\n",
       "      <td>746117.000000</td>\n",
       "      <td>7.461170e+05</td>\n",
       "      <td>7.461170e+05</td>\n",
       "      <td>746117.000000</td>\n",
       "      <td>746117.000000</td>\n",
       "      <td>746117.000000</td>\n",
       "      <td>746117.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>746117.000000</td>\n",
       "      <td>7.461170e+05</td>\n",
       "      <td>7.461170e+05</td>\n",
       "      <td>7.461170e+05</td>\n",
       "      <td>7.461170e+05</td>\n",
       "      <td>7.461170e+05</td>\n",
       "      <td>7.461170e+05</td>\n",
       "      <td>7.461170e+05</td>\n",
       "      <td>7.461170e+05</td>\n",
       "      <td>7.461170e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5195.159152</td>\n",
       "      <td>2.214381e+07</td>\n",
       "      <td>7.664345</td>\n",
       "      <td>8.040212</td>\n",
       "      <td>3.897068e+02</td>\n",
       "      <td>1.392028e+04</td>\n",
       "      <td>165.624361</td>\n",
       "      <td>10.679005</td>\n",
       "      <td>43.385936</td>\n",
       "      <td>59.359873</td>\n",
       "      <td>...</td>\n",
       "      <td>3.998023</td>\n",
       "      <td>-1.412403e+03</td>\n",
       "      <td>9.285406e+04</td>\n",
       "      <td>3.060680e+04</td>\n",
       "      <td>1.367981e+05</td>\n",
       "      <td>7.423070e+04</td>\n",
       "      <td>1.764452e+07</td>\n",
       "      <td>1.009668e+06</td>\n",
       "      <td>1.841303e+07</td>\n",
       "      <td>1.690483e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14144.686896</td>\n",
       "      <td>3.898666e+07</td>\n",
       "      <td>673.933537</td>\n",
       "      <td>877.181297</td>\n",
       "      <td>6.668536e+03</td>\n",
       "      <td>2.130323e+06</td>\n",
       "      <td>579.066493</td>\n",
       "      <td>55.480015</td>\n",
       "      <td>154.968748</td>\n",
       "      <td>226.631737</td>\n",
       "      <td>...</td>\n",
       "      <td>536.762287</td>\n",
       "      <td>8.789839e+05</td>\n",
       "      <td>6.836524e+05</td>\n",
       "      <td>3.546173e+05</td>\n",
       "      <td>9.355221e+05</td>\n",
       "      <td>6.322933e+05</td>\n",
       "      <td>3.457368e+07</td>\n",
       "      <td>6.819789e+06</td>\n",
       "      <td>3.546375e+07</td>\n",
       "      <td>3.438408e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.368707e+08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>6.500000e+01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>4.823000e+04</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.100000e+01</td>\n",
       "      <td>9.900000e+01</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>445.000000</td>\n",
       "      <td>1.134768e+07</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.170000e+02</td>\n",
       "      <td>1.159500e+04</td>\n",
       "      <td>274.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>47.750000</td>\n",
       "      <td>89.882516</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.200000e+01</td>\n",
       "      <td>1.770000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.770000e+02</td>\n",
       "      <td>1.070000e+02</td>\n",
       "      <td>9.367733e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.720346e+06</td>\n",
       "      <td>7.230865e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>65529.000000</td>\n",
       "      <td>1.200000e+08</td>\n",
       "      <td>206446.000000</td>\n",
       "      <td>276072.000000</td>\n",
       "      <td>2.321478e+06</td>\n",
       "      <td>6.270000e+08</td>\n",
       "      <td>24820.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>5940.857143</td>\n",
       "      <td>7049.469004</td>\n",
       "      <td>...</td>\n",
       "      <td>192326.000000</td>\n",
       "      <td>1.380000e+02</td>\n",
       "      <td>1.030000e+08</td>\n",
       "      <td>4.230000e+07</td>\n",
       "      <td>1.030000e+08</td>\n",
       "      <td>1.030000e+08</td>\n",
       "      <td>1.200000e+08</td>\n",
       "      <td>7.350000e+07</td>\n",
       "      <td>1.200000e+08</td>\n",
       "      <td>1.200000e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Destination Port  Flow Duration  Total Fwd Packets  \\\n",
       "count     746117.000000   7.461170e+05      746117.000000   \n",
       "mean        5195.159152   2.214381e+07           7.664345   \n",
       "std        14144.686896   3.898666e+07         673.933537   \n",
       "min            0.000000  -1.000000e+00           1.000000   \n",
       "25%           80.000000   6.500000e+01           1.000000   \n",
       "50%           80.000000   4.823000e+04           2.000000   \n",
       "75%          445.000000   1.134768e+07           6.000000   \n",
       "max        65529.000000   1.200000e+08      206446.000000   \n",
       "\n",
       "       Total Backward Packets  Total Length of Fwd Packets  \\\n",
       "count           746117.000000                 7.461170e+05   \n",
       "mean                 8.040212                 3.897068e+02   \n",
       "std                877.181297                 6.668536e+03   \n",
       "min                  0.000000                 0.000000e+00   \n",
       "25%                  1.000000                 2.000000e+00   \n",
       "50%                  2.000000                 3.100000e+01   \n",
       "75%                  5.000000                 3.170000e+02   \n",
       "max             276072.000000                 2.321478e+06   \n",
       "\n",
       "       Total Length of Bwd Packets  Fwd Packet Length Max  \\\n",
       "count                 7.461170e+05          746117.000000   \n",
       "mean                  1.392028e+04             165.624361   \n",
       "std                   2.130323e+06             579.066493   \n",
       "min                   0.000000e+00               0.000000   \n",
       "25%                   0.000000e+00               2.000000   \n",
       "50%                   9.900000e+01              20.000000   \n",
       "75%                   1.159500e+04             274.000000   \n",
       "max                   6.270000e+08           24820.000000   \n",
       "\n",
       "       Fwd Packet Length Min  Fwd Packet Length Mean  Fwd Packet Length Std  \\\n",
       "count          746117.000000           746117.000000          746117.000000   \n",
       "mean               10.679005               43.385936              59.359873   \n",
       "std                55.480015              154.968748             226.631737   \n",
       "min                 0.000000                0.000000               0.000000   \n",
       "25%                 0.000000                2.000000               0.000000   \n",
       "50%                 0.000000                8.666667               0.000000   \n",
       "75%                 6.000000               47.750000              89.882516   \n",
       "max              2065.000000             5940.857143            7049.469004   \n",
       "\n",
       "       ...  act_data_pkt_fwd  min_seg_size_forward   Active Mean  \\\n",
       "count  ...     746117.000000          7.461170e+05  7.461170e+05   \n",
       "mean   ...          3.998023         -1.412403e+03  9.285406e+04   \n",
       "std    ...        536.762287          8.789839e+05  6.836524e+05   \n",
       "min    ...          0.000000         -5.368707e+08  0.000000e+00   \n",
       "25%    ...          0.000000          2.000000e+01  0.000000e+00   \n",
       "50%    ...          1.000000          2.400000e+01  0.000000e+00   \n",
       "75%    ...          2.000000          3.200000e+01  1.770000e+02   \n",
       "max    ...     192326.000000          1.380000e+02  1.030000e+08   \n",
       "\n",
       "         Active Std    Active Max    Active Min     Idle Mean      Idle Std  \\\n",
       "count  7.461170e+05  7.461170e+05  7.461170e+05  7.461170e+05  7.461170e+05   \n",
       "mean   3.060680e+04  1.367981e+05  7.423070e+04  1.764452e+07  1.009668e+06   \n",
       "std    3.546173e+05  9.355221e+05  6.322933e+05  3.457368e+07  6.819789e+06   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%    0.000000e+00  1.770000e+02  1.070000e+02  9.367733e+06  0.000000e+00   \n",
       "max    4.230000e+07  1.030000e+08  1.030000e+08  1.200000e+08  7.350000e+07   \n",
       "\n",
       "           Idle Max      Idle Min  \n",
       "count  7.461170e+05  7.461170e+05  \n",
       "mean   1.841303e+07  1.690483e+07  \n",
       "std    3.546375e+07  3.438408e+07  \n",
       "min    0.000000e+00  0.000000e+00  \n",
       "25%    0.000000e+00  0.000000e+00  \n",
       "50%    0.000000e+00  0.000000e+00  \n",
       "75%    9.720346e+06  7.230865e+06  \n",
       "max    1.200000e+08  1.200000e+08  \n",
       "\n",
       "[8 rows x 78 columns]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Destination Port', 'Flow Duration', 'Total Fwd Packets',\n",
       "       'Total Backward Packets', 'Total Length of Fwd Packets',\n",
       "       'Total Length of Bwd Packets', 'Fwd Packet Length Max',\n",
       "       'Fwd Packet Length Min', 'Fwd Packet Length Mean',\n",
       "       'Fwd Packet Length Std', 'Bwd Packet Length Max',\n",
       "       'Bwd Packet Length Min', 'Bwd Packet Length Mean',\n",
       "       'Bwd Packet Length Std', 'Flow Bytes/s', 'Flow Packets/s',\n",
       "       'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min',\n",
       "       'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max',\n",
       "       'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean', 'Bwd IAT Std',\n",
       "       'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags',\n",
       "       'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Length',\n",
       "       'Bwd Header Length', 'Fwd Packets/s', 'Bwd Packets/s',\n",
       "       'Min Packet Length', 'Max Packet Length', 'Packet Length Mean',\n",
       "       'Packet Length Std', 'Packet Length Variance', 'FIN Flag Count',\n",
       "       'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count',\n",
       "       'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Down/Up Ratio',\n",
       "       'Average Packet Size', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size',\n",
       "       'Fwd Header Length.1', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk',\n",
       "       'Fwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk',\n",
       "       'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', 'Subflow Fwd Bytes',\n",
       "       'Subflow Bwd Packets', 'Subflow Bwd Bytes', 'Init_Win_bytes_forward',\n",
       "       'Init_Win_bytes_backward', 'act_data_pkt_fwd', 'min_seg_size_forward',\n",
       "       'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean',\n",
       "       'Idle Std', 'Idle Max', 'Idle Min', 'Label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Destination Port               0\n",
       "Flow Duration                  0\n",
       "Total Fwd Packets              0\n",
       "Total Backward Packets         0\n",
       "Total Length of Fwd Packets    0\n",
       "                              ..\n",
       "Idle Mean                      0\n",
       "Idle Std                       0\n",
       "Idle Max                       0\n",
       "Idle Min                       0\n",
       "Label                          0\n",
       "Length: 79, dtype: int64"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "BENIGN                        300000\n",
       "DoS Hulk                      184858\n",
       "PortScan                      127144\n",
       "DDoS                          102422\n",
       "DoS GoldenEye                   8234\n",
       "FTP-Patator                     6350\n",
       "SSH-Patator                     4718\n",
       "DoS slowloris                   4637\n",
       "DoS Slowhttptest                4399\n",
       "Bot                             1573\n",
       "Web Attack � Brute Force        1205\n",
       "Web Attack � XSS                 522\n",
       "Infiltration                      29\n",
       "Web Attack � Sql Injection        17\n",
       "Heartbleed                         9\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "Benign Traffic                    300000\n",
       "DoS Attacks                       202128\n",
       "Port Scanning & Brute Force       138212\n",
       "DDoS Attacks                      102422\n",
       "Other Exploits & Infiltrations      1582\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define mapping dictionary\n",
    "label_mapping = {\n",
    "    'BENIGN': 'Benign Traffic',\n",
    "    'DoS Hulk': 'DoS Attacks',\n",
    "    'DoS GoldenEye': 'DoS Attacks',\n",
    "    'DoS slowloris': 'DoS Attacks',\n",
    "    'DoS Slowhttptest': 'DoS Attacks',\n",
    "    'DDoS': 'DDoS Attacks',\n",
    "    'PortScan': 'Port Scanning & Brute Force',\n",
    "    'FTP-Patator': 'Port Scanning & Brute Force',\n",
    "    'SSH-Patator': 'Port Scanning & Brute Force',\n",
    "    'Web Attack – Brute Force': 'Web-Based Attacks',\n",
    "    'Web Attack – XSS': 'Web-Based Attacks',\n",
    "    'Web Attack – Sql Injection': 'Web-Based Attacks',\n",
    "    'Bot': 'Other Exploits & Infiltrations',\n",
    "    ' Infiltration': 'Other Exploits & Infiltrations',\n",
    "    'Heartbleed': 'Other Exploits & Infiltrations'\n",
    "}\n",
    "\n",
    "# Apply mapping to create a new column with grouped labels\n",
    "df['Label'] = df['Label'].map(label_mapping)\n",
    "df['Label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Destination Port', 'Flow Duration', 'Total Fwd Packets',\n",
       "       'Total Backward Packets', 'Total Length of Fwd Packets',\n",
       "       'Total Length of Bwd Packets', 'Fwd Packet Length Max',\n",
       "       'Fwd Packet Length Min', 'Fwd Packet Length Mean',\n",
       "       'Fwd Packet Length Std', 'Bwd Packet Length Max',\n",
       "       'Bwd Packet Length Min', 'Bwd Packet Length Mean',\n",
       "       'Bwd Packet Length Std', 'Flow Bytes/s', 'Flow Packets/s',\n",
       "       'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min',\n",
       "       'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max',\n",
       "       'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean', 'Bwd IAT Std',\n",
       "       'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags',\n",
       "       'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Length',\n",
       "       'Bwd Header Length', 'Fwd Packets/s', 'Bwd Packets/s',\n",
       "       'Min Packet Length', 'Max Packet Length', 'Packet Length Mean',\n",
       "       'Packet Length Std', 'Packet Length Variance', 'FIN Flag Count',\n",
       "       'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count',\n",
       "       'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Down/Up Ratio',\n",
       "       'Average Packet Size', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size',\n",
       "       'Fwd Header Length.1', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk',\n",
       "       'Fwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk',\n",
       "       'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', 'Subflow Fwd Bytes',\n",
       "       'Subflow Bwd Packets', 'Subflow Bwd Bytes', 'Init_Win_bytes_forward',\n",
       "       'Init_Win_bytes_backward', 'act_data_pkt_fwd', 'min_seg_size_forward',\n",
       "       'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean',\n",
       "       'Idle Std', 'Idle Max', 'Idle Min', 'Label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the grouped labels\n",
    "df['Label'] = label_encoder.fit_transform(df['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0    300000\n",
       "2    202128\n",
       "4    138212\n",
       "1    102422\n",
       "5      1773\n",
       "3      1582\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)  # Convert inf to NaN\n",
    "\n",
    "df.fillna(df.median(), inplace=True)  # Replace NaN with max finite value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Count (target)'}, xlabel='Label'>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Label'].value_counts().plot(kind='bar', title='Count (target)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize features\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X = df.drop(columns=['Label']).values\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "y = df['Label'].values\n",
    "y_encoded = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "   \n",
    "    # Preprocess data\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = preprocess_data(X_scaled, y)\n",
    "    \n",
    "    # Get input shape for the model\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "    num_classes = len(np.unique(y))\n",
    "    \n",
    "    print(f\"Training set shape: {X_train.shape}\")\n",
    "    print(f\"Validation set shape: {X_val.shape}\")\n",
    "    print(f\"Test set shape: {X_test.shape}\")\n",
    "    print(f\"Number of classes: {num_classes}\")\n",
    "    \n",
    "    # Check for class imbalance\n",
    "    class_counts = np.bincount(y_train)\n",
    "    print(\"Class distribution in training set:\", class_counts)\n",
    "    \n",
    "    # Train the model\n",
    "    model, history = train_model(\n",
    "        X_train, y_train, X_val, y_val, \n",
    "        input_shape, num_classes,\n",
    "        # Set use_focal_loss=True for imbalanced datasets\n",
    "    )\n",
    "    \n",
    "    # Evaluate and visualize results\n",
    "    evaluate_model(model, X_test, y_test)\n",
    "    plot_training_history(history)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
